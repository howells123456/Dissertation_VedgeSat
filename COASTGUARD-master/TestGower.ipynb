{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "067dddc8-6cca-40fd-bdc8-c02ec1357bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images available between 2014-01-01 and 2014-12-12:\n",
      "- In Landsat Tier 1 & Sentinel-2 Level-1C:\n",
      "  L7: 26 images\n",
      "  Total: 26 images\n",
      "- In Landsat Tier 2:\n",
      "  L7: 4 images\n",
      "  Total: 4 images\n",
      "retrieving image metadata...\n",
      "Metadata already exists and was loaded\n",
      "18 duplicates\n",
      "10 duplicates\n",
      "2 duplicates\n",
      "1 duplicates\n",
      "1 duplicates\n",
      "0 duplicates\n",
      "0 duplicates\n",
      "saving shapefile to Data/Test/lines\\Test_2014-02-07_2024-12-29_veglines.shp\n",
      "saving shapefile to Data/Test/lines\\Test_2014-02-07_2024-12-29_waterlines.shp\n",
      "finshed\n",
      "Transects already exist and were loaded\n",
      "Transect Intersect GDF exists and was loaded\n",
      "Plot saved under C:\\Users\\charl\\Downloads\\DIX\\COASTGUARD-master\\COASTGUARD-master\\Data\\Test\\plots\\Test_SatVegTimeseriesTrend_Transect_25_30_35.png\n",
      "Plot saved under C:\\Users\\charl\\Downloads\\DIX\\COASTGUARD-master\\COASTGUARD-master\\Data\\Test\\plots\\Test_SatVegTimeseriesTrend_Transect_50.png\n",
      "Plot saved under C:\\Users\\charl\\Downloads\\DIX\\COASTGUARD-master\\COASTGUARD-master\\Data\\Test\\plots\\Test_SatVegTimeseriesTrend_Transect_75.png\n",
      "performing transect intersects on validation lines...\n",
      "formatting into GeoDataFrame...\n",
      "calculating distances between validation and sat lines...\n",
      "ValidInterGDF with intersections created.\n",
      "     LineID  TransectID                                           geometry  \\\n",
      "0         0           0  LINESTRING (423696.421 5713167.57, 423669.615 ...   \n",
      "1         0           1  LINESTRING (423686.271 5713166.206, 423659.943...   \n",
      "2         0           2  LINESTRING (423675.452 5713164.796, 423650.93 ...   \n",
      "3         0           3  LINESTRING (423664.451 5713163.493, 423642.071...   \n",
      "4         0           4  LINESTRING (423650.162 5713162.265, 423636.431...   \n",
      "..      ...         ...                                                ...   \n",
      "236       0         236  LINESTRING (422293.431 5713566.169, 422178.727...   \n",
      "237       0         237  LINESTRING (422285.449 5713560.571, 422170.336...   \n",
      "238       0         238  LINESTRING (422277.33 5713554.852, 422162.104 ...   \n",
      "239       0         239  LINESTRING (422269.219 5713549.129, 422153.873...   \n",
      "240       0         240  LINESTRING (422261.081 5713543.381, 422145.675...   \n",
      "\n",
      "                                            reflinepnt  \\\n",
      "0    [POINT (423682.9459003482 5713267.200005796), ...   \n",
      "1    [POINT (423672.9569309752 5713266.465843358), ...   \n",
      "2    [POINT (423662.98219644034 5713265.732727142),...   \n",
      "3    [POINT (423653.0202518722 5713265.0005509555),...   \n",
      "4    [POINT (423643.14223453583 5713264.274543194),...   \n",
      "..                                                 ...   \n",
      "236  [POINT (422236.12075262185 5713648.029524876),...   \n",
      "237  [POINT (422227.9371856772 5713642.282750265), ...   \n",
      "238  [POINT (422219.75349454954 5713636.535888449),...   \n",
      "239  [POINT (422211.56978470803 5713630.789013491),...   \n",
      "240  [POINT (422203.38604051067 5713625.042114408),...   \n",
      "\n",
      "                                                 dates  \\\n",
      "0    [2014-04-13, 2014-04-21, 2014-04-28, 2014-05-1...   \n",
      "1    [2014-04-13, 2014-04-21, 2014-04-28, 2014-05-1...   \n",
      "2    [2014-04-13, 2014-04-21, 2014-04-28, 2014-05-1...   \n",
      "3    [2014-04-13, 2014-04-21, 2014-04-28, 2014-05-1...   \n",
      "4    [2014-04-13, 2014-04-21, 2014-04-28, 2014-05-1...   \n",
      "..                                                 ...   \n",
      "236  [2014-03-11, 2014-04-13, 2014-04-21, 2014-05-1...   \n",
      "237  [2014-03-11, 2014-04-13, 2014-04-21, 2014-05-1...   \n",
      "238  [2014-03-11, 2014-04-13, 2014-04-21, 2014-05-1...   \n",
      "239  [2014-03-11, 2014-04-13, 2014-04-21, 2014-05-1...   \n",
      "240  [2014-03-11, 2014-04-13, 2014-04-21, 2014-05-1...   \n",
      "\n",
      "                                                 times  \\\n",
      "0    [11:04:46.368000, 11:01:55.277000, 11:08:08.94...   \n",
      "1    [11:04:46.368000, 11:01:55.277000, 11:08:08.94...   \n",
      "2    [11:04:46.368000, 11:01:55.277000, 11:08:08.94...   \n",
      "3    [11:04:46.368000, 11:01:55.277000, 11:08:08.94...   \n",
      "4    [11:04:46.368000, 11:01:55.277000, 11:08:08.94...   \n",
      "..                                                 ...   \n",
      "236  [11:07:44.971000, 11:04:46.368000, 11:01:55.27...   \n",
      "237  [11:07:44.971000, 11:04:46.368000, 11:01:55.27...   \n",
      "238  [11:07:44.971000, 11:04:46.368000, 11:01:55.27...   \n",
      "239  [11:07:44.971000, 11:04:46.368000, 11:01:55.27...   \n",
      "240  [11:07:44.971000, 11:04:46.368000, 11:01:55.27...   \n",
      "\n",
      "                                              filename  \\\n",
      "0    [LANDSAT/LC08/C02/T1_TOA/LC08_203024_20140413,...   \n",
      "1    [LANDSAT/LC08/C02/T1_TOA/LC08_203024_20140413,...   \n",
      "2    [LANDSAT/LC08/C02/T1_TOA/LC08_203024_20140413,...   \n",
      "3    [LANDSAT/LC08/C02/T1_TOA/LC08_203024_20140413,...   \n",
      "4    [LANDSAT/LC08/C02/T1_TOA/LC08_203024_20140413,...   \n",
      "..                                                 ...   \n",
      "236  [LANDSAT/LE07/C02/T1_TOA/LE07_204024_20140311,...   \n",
      "237  [LANDSAT/LE07/C02/T1_TOA/LE07_204024_20140311,...   \n",
      "238  [LANDSAT/LE07/C02/T1_TOA/LE07_204024_20140311,...   \n",
      "239  [LANDSAT/LE07/C02/T1_TOA/LE07_204024_20140311,...   \n",
      "240  [LANDSAT/LE07/C02/T1_TOA/LE07_204024_20140311,...   \n",
      "\n",
      "                                            cloud_cove  \\\n",
      "0    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "..                                                 ...   \n",
      "236  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "237  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "238  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "239  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "240  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                                   idx  \\\n",
      "0    [5, 2, 121, 6, 61, 125, 126, 63, 66, 8, 71, 10...   \n",
      "1    [5, 2, 121, 6, 61, 125, 126, 63, 66, 8, 71, 10...   \n",
      "2    [5, 2, 121, 6, 61, 125, 126, 63, 66, 8, 71, 10...   \n",
      "3    [5, 2, 121, 6, 61, 125, 126, 63, 66, 8, 71, 10...   \n",
      "4    [5, 2, 121, 6, 61, 125, 126, 63, 66, 8, 71, 10...   \n",
      "..                                                 ...   \n",
      "236  [119, 5, 2, 122, 6, 61, 125, 62, 126, 63, 66, ...   \n",
      "237  [119, 5, 2, 122, 6, 61, 125, 62, 126, 63, 66, ...   \n",
      "238  [119, 5, 2, 122, 6, 61, 125, 62, 126, 63, 66, ...   \n",
      "239  [119, 5, 2, 122, 6, 61, 125, 62, 126, 63, 66, ...   \n",
      "240  [119, 5, 2, 122, 6, 61, 125, 62, 126, 63, 66, ...   \n",
      "\n",
      "                                            vthreshold  ... oldyoungT  \\\n",
      "0    [0.208000000000001, -0.147999999999999, 0.3340...  ...   10.7134   \n",
      "1    [0.208000000000001, -0.147999999999999, 0.3340...  ...   10.7134   \n",
      "2    [0.208000000000001, -0.147999999999999, 0.3340...  ...   10.7134   \n",
      "3    [0.208000000000001, -0.147999999999999, 0.3340...  ...   10.7134   \n",
      "4    [0.208000000000001, -0.147999999999999, 0.3340...  ...   10.7134   \n",
      "..                                                 ...  ...       ...   \n",
      "236  [0.228000000000001, 0.208000000000001, -0.1479...  ...   10.8038   \n",
      "237  [0.228000000000001, 0.208000000000001, -0.1479...  ...   10.8038   \n",
      "238  [0.228000000000001, 0.208000000000001, -0.1479...  ...   10.8038   \n",
      "239  [0.228000000000001, 0.208000000000001, -0.1479...  ...   10.8038   \n",
      "240  [0.228000000000001, 0.208000000000001, -0.1479...  ...   10.8038   \n",
      "\n",
      "    oldyoungRt recentT recentRt  \\\n",
      "0         0.71  0.0274 -1547.05   \n",
      "1         0.46  0.0274 -2142.86   \n",
      "2         0.45  0.0274 -2405.99   \n",
      "3         0.56  0.0274 -2424.29   \n",
      "4         0.22  0.0274 -2195.05   \n",
      "..         ...     ...      ...   \n",
      "236       0.47  0.0274  -761.57   \n",
      "237       0.32  0.0274  -751.46   \n",
      "238       0.25  0.0274  -777.74   \n",
      "239       0.32  0.0274  -811.11   \n",
      "240       0.45  0.0274  2378.38   \n",
      "\n",
      "                                             normdists  \\\n",
      "0    [-28.11755337556137, -17.750169123492867, -35....   \n",
      "1    [-28.092110825807495, -12.090108678258304, -33...   \n",
      "2    [-23.382007321901767, -8.282163572021659, -30....   \n",
      "3    [-18.177576527883275, -5.34121926308876, -27.3...   \n",
      "4    [-12.96868265237974, -3.2420537983390005, -24....   \n",
      "..                                                 ...   \n",
      "236  [14.545756797769869, 18.518872918554123, -47.6...   \n",
      "237  [15.808676636433702, 15.087798026524908, -45.1...   \n",
      "238  [-24.270318222256762, 18.92522295413673, -41.8...   \n",
      "239  [11.161709681207867, 27.754148065252167, -38.0...   \n",
      "240  [-12.044433683547354, 37.297447087413374, -32....   \n",
      "\n",
      "                                                Vdates  \\\n",
      "0                                                   []   \n",
      "1                                                   []   \n",
      "2                                                   []   \n",
      "3                                                   []   \n",
      "4                                                   []   \n",
      "..                                                 ...   \n",
      "236  [2024-05-24, 2023-04-13, 2022-05-13, 2021-04-2...   \n",
      "237  [2024-05-24, 2023-04-13, 2022-05-13, 2021-04-2...   \n",
      "238  [2024-05-24, 2023-04-13, 2022-05-13, 2021-04-2...   \n",
      "239  [2024-05-24, 2023-04-13, 2022-05-13, 2021-04-2...   \n",
      "240  [2024-05-24, 2023-04-13, 2022-05-13, 2021-04-2...   \n",
      "\n",
      "                                                Vdists  \\\n",
      "0                                                   []   \n",
      "1                                                   []   \n",
      "2                                                   []   \n",
      "3                                                   []   \n",
      "4                                                   []   \n",
      "..                                                 ...   \n",
      "236  [134.4477092410835, 134.4477092410835, 132.940...   \n",
      "237  [127.29524831899028, 127.29524831899028, 127.2...   \n",
      "238  [126.30904061861712, 154.56440506402345, 154.5...   \n",
      "239  [129.70702145721262, 165.30385306643524, 162.6...   \n",
      "240  [129.61301371460982, 141.41990137342734, 162.9...   \n",
      "\n",
      "                                             Vinterpnt  \\\n",
      "0                                                   []   \n",
      "1                                                   []   \n",
      "2                                                   []   \n",
      "3                                                   []   \n",
      "4                                                   []   \n",
      "..                                                 ...   \n",
      "236  [POINT Z (422216.3229610612 5713676.307869065 ...   \n",
      "237  [POINT Z (422212.18236765004 5713664.666867062...   \n",
      "238  [POINT Z (422204.559551043 5713658.0916256895 ...   \n",
      "239  [POINT Z (422194.41320760857 5713655.091062262...   \n",
      "240  [POINT Z (422186.2906397304 5713649.23866089 0...   \n",
      "\n",
      "                                            valsatdist  \\\n",
      "0    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "1    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "2    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "3    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "4    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "..                                                 ...   \n",
      "236  [-12.329650674037381, -8.356534553253127, -74....   \n",
      "237  [-6.721092328237731, -7.441970938146525, -67.7...   \n",
      "238  [-44.29512135754666, -1.099580181153172, -61.8...   \n",
      "239  [-4.762979540764093, 11.829458843280207, -54.0...   \n",
      "240  [-42.60938691502611, 6.732493855934621, -63.15...   \n",
      "\n",
      "                                            valsatdate  \n",
      "0    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...  \n",
      "1    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...  \n",
      "2    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...  \n",
      "3    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...  \n",
      "4    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...  \n",
      "..                                                 ...  \n",
      "236  [2014-04-08, 2014-04-08, 2014-04-08, 2014-04-0...  \n",
      "237  [2014-04-08, 2014-04-08, 2014-04-08, 2014-04-0...  \n",
      "238  [2014-04-08, 2014-04-08, 2014-04-08, 2014-04-0...  \n",
      "239  [2014-04-08, 2014-04-08, 2014-04-08, 2014-04-0...  \n",
      "240  [2014-04-08, 2014-04-08, 2014-04-08, 2014-04-0...  \n",
      "\n",
      "[241 rows x 27 columns]\n",
      "figure saved under C:\\Users\\charl\\Downloads\\DIX\\COASTGUARD-master\\COASTGUARD-master\\Data\\Test\\plots\\Test_Validation_Satellite_Distances_Violin_0to59.png\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 349\u001b[0m\n\u001b[0;32m    346\u001b[0m     PlotTitle \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy of Transects \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(TransectIDs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(TransectIDs[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    347\u001b[0m     PlottingSeaborn\u001b[38;5;241m.\u001b[39mSatViolin(sitename,VeglineGDF,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdates\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    348\u001b[0m                             ,ValidInterGDF,TransectIDs, PlotTitle)\n\u001b[1;32m--> 349\u001b[0m     \u001b[43mPlottingSeaborn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSatPDF\u001b[49m\u001b[43m(\u001b[49m\u001b[43msitename\u001b[49m\u001b[43m,\u001b[49m\u001b[43mVeglineGDF\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdates\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mValidInterGDF\u001b[49m\u001b[43m,\u001b[49m\u001b[43mTransectIDs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPlotTitle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m     Plotting\u001b[38;5;241m.\u001b[39mSatRegress(sitename,VeglineGDF,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdates\u001b[39m\u001b[38;5;124m'\u001b[39m,ValidInterGDF,TransectIDs, PlotTitle)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m#%% Quantify errors between validation and satellite derived lines\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;66;03m# EDIT ME: List of transect ID tuples (startID, finishID\u001b[39;00m\n",
      "File \u001b[1;32m~\\Downloads\\DIX\\COASTGUARD-master\\COASTGUARD-master\\Toolshed\\PlottingSeaborn.py:477\u001b[0m, in \u001b[0;36mSatPDF\u001b[1;34m(sitename, SatGDF, DatesCol, ValidInterGDF, TransectIDs, PlotTitle)\u001b[0m\n\u001b[0;32m    475\u001b[0m colind \u001b[38;5;241m=\u001b[39m [df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(sat) \u001b[38;5;28;01mfor\u001b[39;00m sat \u001b[38;5;129;01min\u001b[39;00m sats]\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# set the date legend label for each date to corresponding satname colour\u001b[39;00m\n\u001b[1;32m--> 477\u001b[0m [leg1\u001b[38;5;241m.\u001b[39mget_texts()[ind]\u001b[38;5;241m.\u001b[39mset_color(c) \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m colind]\n\u001b[0;32m    479\u001b[0m \u001b[38;5;66;03m# get median of only the columns that match each sat name\u001b[39;00m\n\u001b[0;32m    480\u001b[0m concatl \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\Downloads\\DIX\\COASTGUARD-master\\COASTGUARD-master\\Toolshed\\PlottingSeaborn.py:477\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    475\u001b[0m colind \u001b[38;5;241m=\u001b[39m [df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(sat) \u001b[38;5;28;01mfor\u001b[39;00m sat \u001b[38;5;129;01min\u001b[39;00m sats]\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# set the date legend label for each date to corresponding satname colour\u001b[39;00m\n\u001b[1;32m--> 477\u001b[0m [\u001b[43mleg1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mset_color(c) \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m colind]\n\u001b[0;32m    479\u001b[0m \u001b[38;5;66;03m# get median of only the columns that match each sat name\u001b[39;00m\n\u001b[0;32m    480\u001b[0m concatl \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "#%% Imports and Initialisation\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "from datetime import datetime\n",
    "from Toolshed import Download, Toolbox, VegetationLine, Plotting, PlottingSeaborn, Transects\n",
    "import ee\n",
    "import geopandas as gpd\n",
    "\n",
    "ee.Initialize()\n",
    "\n",
    "\n",
    "\n",
    "#%% EDIT ME: Requirements\n",
    "\n",
    "\n",
    "# Define name of site\n",
    "sitename = 'Test'\n",
    "\n",
    "# Date range\n",
    "dates = ['2014-01-01', '2014-12-12']\n",
    "\n",
    "# Satellite missions\n",
    "# Input a list of containing any/all of 'L5', 'L7', 'L8', 'L9', 'S2', 'PSScene4Band'\n",
    "# L5: 1984-2013; L7: 1999-2017 (SLC error from 2003); L8: 2013-present; S2: 2014-present; L9: 2021-present\n",
    "sat_list = ['L7']\n",
    "\n",
    "# Cloud threshold for screening out cloudy imagery (0.5 or 50% recommended)\n",
    "cloud_thresh = 0.5\n",
    "\n",
    "# Extract shoreline (wet-dry boundary) as well as veg edge\n",
    "wetdry = True\n",
    "\n",
    "# Reference shoreline/veg line shapefile name (should be stored in a folder called referenceLines in Data)\n",
    "referenceLineShp = 'Three Cliffs Bay.shp'\n",
    "# Maximum amount in metres by which to buffer the reference line for capturing veg edges within\n",
    "max_dist_ref = 100\n",
    "\n",
    "\n",
    "#%% Set Up Site Directory\n",
    "# Directory where the data will be stored\n",
    "filepath = Toolbox.CreateFileStructure(sitename, sat_list)\n",
    "\n",
    "# Return AOI from reference line bounding box and save AOI folium map HTML in sitename directory\n",
    "referenceLinePath = os.path.join(filepath, 'referenceLines', referenceLineShp)\n",
    "referenceLineDF = gpd.read_file(referenceLinePath)\n",
    "polygon, point, lonmin, lonmax, latmin, latmax = Toolbox.AOIfromLine(referenceLinePath, max_dist_ref, sitename)\n",
    "\n",
    "# It's recommended to convert the polygon to the smallest rectangle (sides parallel to coordinate axes)       \n",
    "polygon = Toolbox.smallest_rectangle(polygon)\n",
    "\n",
    "\n",
    "#%% Compile Input Settings for Imagery\n",
    "\n",
    "if len(dates)>2:\n",
    "    daterange='no'\n",
    "else:\n",
    "    daterange='yes'\n",
    "years = list(Toolbox.daterange(datetime.strptime(dates[0],'%Y-%m-%d'), datetime.strptime(dates[-1],'%Y-%m-%d')))\n",
    "\n",
    "# Put all the inputs into a dictionary\n",
    "inputs = {'polygon': polygon, 'dates': dates, 'daterange':daterange, 'sat_list': sat_list, 'sitename': sitename, 'filepath':filepath}\n",
    "\n",
    "\n",
    "#%% Image Retrieval\n",
    "\n",
    "# Before downloading the images, check how many images are available for your inputs\n",
    "inputs = Download.check_images_available(inputs)\n",
    "\n",
    "\n",
    "#%% Image Download\n",
    "\n",
    "# If you want to include Landsat 7 but DON'T want to include Scan Line Corrector affected images, set SLC=False\n",
    "Sat = Download.RetrieveImages(inputs, SLC=False)\n",
    "metadata = Download.CollectMetadata(inputs, Sat)\n",
    "\n",
    "\n",
    "#%% Vegetation Edge Settings\n",
    "# ONLY EDIT IF ADJUSTMENTS ARE NEEDED\n",
    "\n",
    "LinesPath = 'Data/' + sitename + '/lines'\n",
    "\n",
    "if os.path.isdir(LinesPath) is False:\n",
    "    os.mkdir(LinesPath)\n",
    "    \n",
    "projection_epsg, _ = Toolbox.FindUTM(polygon[0][0][1],polygon[0][0][0])\n",
    "\n",
    "settings = {\n",
    "    # general parameters:\n",
    "    'cloud_thresh': cloud_thresh,        # threshold on maximum cloud cover\n",
    "    'output_epsg': projection_epsg,     # epsg code of spatial reference system desired for the output   \n",
    "    'wetdry': wetdry,              # extract wet-dry boundary as well as veg\n",
    "    # quality control:\n",
    "    'check_detection': False,    # if True, shows each shoreline detection to the user for validation\n",
    "    'adjust_detection': False,  # if True, allows user to adjust the postion of each shoreline by changing the threhold\n",
    "    'save_figure': True,        # if True, saves a figure showing the mapped shoreline for each image\n",
    "    # [ONLY FOR ADVANCED USERS] shoreline detection parameters:\n",
    "    'min_beach_area': 200,     # minimum area (in metres^2) for an object to be labelled as a beach\n",
    "    'buffer_size': 250,         # radius (in metres) for buffer around sandy pixels considered in the shoreline detection\n",
    "    'min_length_sl': 500,       # minimum length (in metres) of shoreline perimeter to be valid\n",
    "    'cloud_mask_issue': False,  # switch this parameter to True if sand pixels are masked (in black) on many images  \n",
    "    # add the inputs defined previously\n",
    "    'inputs': inputs,\n",
    "    'projection_epsg': projection_epsg,\n",
    "    'year_list': years\n",
    "}\n",
    "\n",
    "\n",
    "#%% Vegetation Edge Reference Line Load-In\n",
    "\n",
    "referenceLine, ref_epsg = Toolbox.ProcessRefline(referenceLinePath,settings)\n",
    "\n",
    "settings['reference_shoreline'] = referenceLine\n",
    "settings['ref_epsg'] = ref_epsg\n",
    "# Distance to buffer reference line by (this is in metres)\n",
    "settings['max_dist_ref'] = max_dist_ref\n",
    "\n",
    "# Reference Image (path to TIF) for Coregistration\n",
    "settings['reference_coreg_im'] = os.path.join(filepath, sitename, 'jpg_files')\n",
    "# if no coreg to be performed\n",
    "settings['reference_coreg_im'] = None\n",
    "\n",
    "\n",
    "# #%% Vegetation Line Extraction\n",
    "# \"\"\"\n",
    "# OPTION 1: Run extraction tool and return output veg edges as a dictionary of lines\n",
    "# \"\"\"\n",
    "\n",
    "# output, output_latlon, output_proj = VegetationLine.extract_veglines(metadata, settings, polygon, dates)\n",
    "\n",
    "\n",
    "#%% Vegetation Line Extraction Load-In\n",
    "\"\"\"\n",
    "OPTION 2: Load in pre-existing outputs\n",
    "\"\"\"\n",
    "\n",
    "output, output_latlon, output_proj = Toolbox.ReadOutput(inputs)\n",
    "\n",
    "    \n",
    "\n",
    "#%% Remove Duplicate Lines\n",
    "# For images taken on the same date by the same satellite, keep only the longest line\n",
    "\n",
    "output = Toolbox.RemoveDuplicates(output) \n",
    "\n",
    "\n",
    "#%% Save Veglines as Local Shapefiles\n",
    "\n",
    "# Save output veglines \n",
    "Toolbox.SaveConvShapefiles(output, LinesPath, sitename, settings['output_epsg'])\n",
    "# Save output shorelines if they were generated\n",
    "if settings['wetdry'] == True:\n",
    "    Toolbox.SaveConvShapefiles_Water(output, LinesPath, sitename, settings['output_epsg'])\n",
    "\n",
    "print('finshed')\n",
    "#return\n",
    "#%% EDIT ME: Define Settings for Cross-shore Transects\n",
    "\n",
    "SmoothingWindowSize = 21 \n",
    "NoSmooths = 0\n",
    "TransectSpacing = 400\n",
    "DistanceInland = 200\n",
    "DistanceOffshore = 100\n",
    "\n",
    "# provide average beach slope for site, for calculating corrected beach widths\n",
    "beachslope = 0.24\n",
    "# beachslope = None\n",
    "\n",
    "\n",
    "#%% Create Cross-shore Transects\n",
    "\n",
    "LinesPath = 'Data/' + sitename + '/lines'\n",
    "VeglineShp = glob.glob(LinesPath+'/*veglines.shp')\n",
    "VeglineGDF = gpd.read_file(VeglineShp[0])\n",
    "#WaterlineShp = glob.glob(LinesPath+'/*waterlines.shp')\n",
    "#WaterlineGDF = gpd.read_file(WaterlineShp[0])\n",
    "# Produces Transects for the reference line\n",
    "TransectSpec =  os.path.join(LinesPath, sitename+'_Transects.shp')\n",
    "\n",
    "# If transects already exist, load them in\n",
    "if os.path.isfile(TransectSpec[:-3]+'pkl') is False:\n",
    "    TransectGDF = Transects.ProduceTransects(settings, SmoothingWindowSize, NoSmooths, TransectSpacing, DistanceInland, DistanceOffshore, LinesPath, referenceLineShp)\n",
    "else:\n",
    "    print('Transects already exist and were loaded')\n",
    "    with open(TransectSpec[:-3]+'pkl', 'rb') as Tfile: \n",
    "        TransectGDF = pickle.load(Tfile)\n",
    "    \n",
    "# make new transect intersections folder\n",
    "if os.path.isdir(os.path.join(filepath, sitename, 'intersections')) is False:\n",
    "    os.mkdir(os.path.join(filepath, sitename, 'intersections'))\n",
    "\n",
    "#%% Transect-Veg Intersections\n",
    "# Create (or load) intersections with all satellite lines per transect\n",
    "shp_path = os.path.join(filepath, sitename, 'intersections', sitename + '_transect_intersects.shp')\n",
    "\n",
    "if os.path.isfile(os.path.join(filepath, sitename, 'intersections', sitename + '_transect_intersects.pkl')):\n",
    "    print('Transect Intersect GDF exists and was loaded')\n",
    "    with open(os.path.join\n",
    "              (filepath , sitename, 'intersections', sitename + '_transect_intersects.pkl'), 'rb') as f:\n",
    "        TransectInterGDF = pickle.load(f)\n",
    "    # # Save as Shapefile\n",
    "    # TransectInterGDF.to_file(shp_path, driver=\"ESRI Shapefile\")\n",
    "else:\n",
    "    # Get intersections\n",
    "    TransectInterGDF = Transects.GetIntersections(LinesPath, TransectGDF, VeglineGDF)\n",
    "    # Save newly intersected transects as shapefile\n",
    "    TransectInterGDF = Transects.SaveIntersections(TransectInterGDF, VeglineGDF, LinesPath, sitename)\n",
    "    # Repopulate dict with intersection distances along transects normalised to transect midpoints\n",
    "    TransectInterGDF = Transects.CalculateChanges(TransectInterGDF)\n",
    "    \n",
    "    with open(os.path.join(filepath, sitename, 'intersections', sitename + '_transect_intersects.pkl'), 'wb') as f:\n",
    "        pickle.dump(TransectInterGDF, f)\n",
    "    # # Save as Shapefile\n",
    "    # TransectInterGDF.to_file(shp_path, driver=\"ESRI Shapefile\")\n",
    "\n",
    "\n",
    "##%% Transect-Water Intersections\n",
    "\n",
    "# if os.path.isfile(os.path.join(filepath, sitename, 'intersections', sitename + '_transect_water_intersects.pkl')):\n",
    "#     print('Transect Intersect + Water GDF exists and was loaded')\n",
    "#     with open(os.path.join\n",
    "#               (filepath , sitename, 'intersections', sitename + '_transect_water_intersects.pkl'), 'rb') as f:\n",
    "#         TransectInterGDFWater = pickle.load(f)\n",
    "# else:        \n",
    "#     if settings['wetdry'] == True:\n",
    "#         TransectInterGDFWater = Transects.GetWaterIntersections(BasePath, TransectGDF, TransectInterGDF, WaterlineGDF, settings, output)  \n",
    "    \n",
    "#     with open(os.path.join(filepath, sitename, 'intersections', sitename + '_transect_water_intersects.pkl'), 'wb') as f:\n",
    "#         pickle.dump(TransectInterGDFWater, f)\n",
    "\n",
    "#%% Transect-Waves Intersections (needs to be before tidal corrections if using runup as well)\n",
    "# This is for comparing veg edge positions with nearshore wave conditions at the time the image was taken. \n",
    "# Note: this requires you to have a Copernicus Marine Service (CMEMS) account with access to their hindcast model, \n",
    "# as you will be asked for a username and password.\n",
    "\n",
    "# #if os.path.isfile(os.path.join(filepath, sitename, 'intersections', sitename + '_transect_wave_intersects.pkl')):\n",
    "#     #print('Transect Intersect + Wave GDF exists and was loaded')\n",
    "#    # with open(os.path.join\n",
    "#               (filepath , sitename, 'intersections', sitename + '_transect_wave_intersects.pkl'), 'rb') as f:\n",
    "#         TransectInterGDFWave = pickle.load(f)\n",
    "# #else:\n",
    "#     TransectInterGDFWave = Transects.WavesIntersect(settings, TransectInterGDF, BasePath, output, lonmin, lonmax, latmin, latmax)\n",
    "    \n",
    "#     with open(os.path.join(filepath, sitename, 'intersections', sitename + '_transect_wave_intersects.pkl'), 'wb') as f:\n",
    "#         pickle.dump(TransectInterGDFWave, f)\n",
    "\n",
    "#%% Additional wave-based WL metrics\n",
    "# This is for comparing shoreline change with vegetation change, and for quantifying the beach width between the two for each image. If you would like to \n",
    "# include runup in your waterline corrections, add `TransectInterGDFWave` to `GetWaterIntersections()`:\n",
    "    # TransectInterGDFWater = Transects.GetWaterIntersections(\n",
    "    # BasePath, TransectGDF, TransectInterGDF, WaterlineGDF, settings, output, TransectInterGDFWave, beachslope)\n",
    "\n",
    "# If you want to include runup AND calculate slopes using CoastSat.slope (recommended), exclude the `beachslope` variable:\n",
    "    # TransectInterGDFWater = Transects.GetWaterIntersections(\n",
    "    # BasePath, TransectGDF, TransectInterGDF, WaterlineGDF, settings, output, TransectInterGDFWave)\n",
    "\n",
    "# if 'wlcorrdist' not in TransectInterGDFWater.columns:\n",
    "#     # Tidal correction to get corrected distances along transects\n",
    "#     TransectInterGDFWater = Transects.WLCorrections(settings, output, TransectInterGDFWater, TransectInterGDFWave)     \n",
    "#     # Calculate width between VE and corrected WL\n",
    "#     TransectInterGDFWater = Transects.CalcBeachWidth(settings, TransectGDF, TransectInterGDFWater)\n",
    "#     # Calculate rates of change on corrected WL and save as Transects shapefile\n",
    "#     TransectInterGDFWater = Transects.SaveWaterIntersections(TransectInterGDFWater, WaterlineGDF,  BasePath, sitename)\n",
    "#     with open(os.path.join(filepath, sitename, 'intersections', sitename + '_transect_water_intersects.pkl'), 'wb') as f:\n",
    "#         pickle.dump(TransectInterGDFWater, f)\n",
    "\n",
    "\n",
    "# #%% Transect-Topo Intersections\n",
    "# # EDIT ME: Path to slope raster for extracting slope values\n",
    "# TIF = '/path/to/Slope_Raster.tif'\n",
    "\n",
    "# if os.path.isfile(os.path.join(filepath, sitename, 'intersections', sitename + '_transect_topo_intersects.pkl')):\n",
    "#     print('Transect Intersect + Topo GDF exists and was loaded')\n",
    "#     with open(os.path.join\n",
    "#               (filepath , sitename, 'intersections', sitename + '_transect_topo_intersects.pkl'), 'rb') as f:\n",
    "#         TransectInterGDFTopo = pickle.load(f)\n",
    "# else:\n",
    "#     # Update Transects with Transition Zone widths and slope if available\n",
    "#     TransectInterGDFTopo = Transects.TZIntersect(settings, TransectInterGDF, VeglineGDF, LinesPath)\n",
    "#     TransectInterGDFTopo = Transects.SlopeIntersect(settings, TransectInterGDFTopo, VeglineGDF, LinesPath, TIF)\n",
    "    \n",
    "#     with open(os.path.join(filepath, sitename, 'intersections', sitename + '_transect_topo_intersects.pkl'), 'wb') as f:\n",
    "#         pickle.dump(TransectInterGDFTopo, f)\n",
    "\n",
    "\n",
    "#%% Timeseries Plotting\n",
    "\n",
    "# EDIT ME: Select transect ID to plot\n",
    "TransectIDs = [[25,30,35],50,75]\n",
    "for TransectID in TransectIDs:\n",
    "     #Plot timeseries of cross-shore veg position\n",
    "      Plotting.VegTimeseries(sitename, TransectInterGDF, TransectID, Hemisphere='N')\n",
    "      #If plotting veg and water lines together\n",
    "      # if settings['wetdry']:\n",
    "      #    Plotting.VegWaterTimeseries(sitename, TransectInterGDFWater, TransectID, Hemisphere='N')\n",
    "\n",
    "    \n",
    "# #%% Beach Width Plotting\n",
    "\n",
    "# # Select transect ID to plot\n",
    "# TransectIDs = [[25,30,35],50,75]\n",
    "# for TransectID in TransectIDs:\n",
    "#     # Plot timeseries of cross-shore width between water edge and veg edge \n",
    "#     Plotting.WidthTimeseries(sitename, TransectInterGDFWater, TransectID, Hemisphere='N')\n",
    "\n",
    "\n",
    "#%% EDIT ME: Validation Settings\n",
    "# Most likely you won't need to validate your lines, but if you do, edit these parameters\n",
    "\n",
    "# Name of date column in validation edges shapefile (case sensitive!) \n",
    "DatesCol = 'dates'\n",
    "ValidationShp = ValidationShp = 'C:\\\\Users\\\\charl\\\\Downloads\\\\Repro3cliffs.shp'\n",
    "\n",
    "#%% Satellite Edges Validation\n",
    "\n",
    "validpath = os.path.join(os.getcwd(), 'Data', sitename, 'validation')\n",
    "\n",
    "if os.path.isfile(os.path.join(validpath, sitename + '_valid_intersects.pkl')) and False is True: \n",
    "    print('ValidDict exists and was loaded')\n",
    "    with open(os.path.join(validpath, sitename + '_valid_intersects.pkl'), 'rb') as f:\n",
    "        ValidInterGDF = pickle.load(f)\n",
    "else:\n",
    "    ValidInterGDF = Transects.ValidateSatIntersects(sitename, ValidationShp, DatesCol, TransectGDF, TransectInterGDF)\n",
    "    with open(os.path.join(validpath, sitename + '_valid_intersects.pkl'), 'wb') as f:\n",
    "        pickle.dump(ValidInterGDF, f)\n",
    "\n",
    "print(ValidInterGDF)\n",
    "#%% Validation Plots\n",
    "# EDIT ME: List of transect ID tuples (startID, finishID)\n",
    "TransectIDList = [(0,59),(60,119),(120,179),(180,240)]\n",
    "\n",
    "for TransectIDs in TransectIDList:\n",
    "    PlotTitle = 'Accuracy of Transects ' + str(TransectIDs[0]) + ' to ' + str(TransectIDs[1])\n",
    "    PlottingSeaborn.SatViolin(sitename,VeglineGDF,'dates'\n",
    "                            ,ValidInterGDF,TransectIDs, PlotTitle)\n",
    "    PlottingSeaborn.SatPDF(sitename,VeglineGDF,'dates',ValidInterGDF,TransectIDs, PlotTitle)\n",
    "    Plotting.SatRegress(sitename,VeglineGDF,'dates',ValidInterGDF,TransectIDs, PlotTitle)\n",
    "\n",
    "    \n",
    "#%% Quantify errors between validation and satellite derived lines\n",
    "# EDIT ME: List of transect ID tuples (startID, finishID\n",
    "\n",
    "for TransectIDs in TransectIDList:\n",
    "    Toolbox.QuantifyErrors(sitename, VeglineGDF,'dates',ValidInterGDF,TransectIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76d882-8d7a-40da-a7d4-84dc030bbfc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf890ce-fcce-4a2e-b042-b63a57d9250c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coastguard",
   "language": "python",
   "name": "coastguard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
